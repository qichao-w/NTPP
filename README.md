# ðŸ¦œ Parrot: Seamless Spoken Dialogue Interaction with Double-Channel Large Language Models

## Abstract
We present Parrot, an innovative spoken dialogue language model with a unique pre-training and supervised fine-tuning (SFT) pipeline. Our approach uses both single-channel audio data and double-channel spoken dialogue data to train a textless speech language model.

<!-- ![Parrot](assert/audio-introduction.png) -->
<img src="assert/audio-introduction.png" alt="Parrot" width="500"/>

<!-- <embed src="assert/audio-introduction.pdf" width="600" height="500" type="application/pdf"> -->

Key features:
- Pre-training: Transform single-channel audio into discrete tokens for next-token prediction
- SFT: Novel "next-token-pair prediction" objective for natural conversation comprehension
- Result: More natural and fluid spoken interactions compared to baseline approaches

<img src="assert/audio_sft.png" alt="Parrot" width="500"/>

## Installation

```bash
git clone https://github.com/anonymous/parrot.git
cd parrot
python -m venv venv
source venv/bin/activate  # On Windows, use `venv\Scripts\activate`
pip install -r requirements.txt
```

## Usage

1. Prepare audio data for pre-training and fine-tuning
2. Pre-train: `python pretrain.py --input_data path/to/single_channel_data`
3. Fine-tune: `python finetune.py --input_data path/to/double_channel_data`
4. Inference: `python inference.py --input_audio path/to/input.wav`

For detailed instructions, see the `docs` folder.

## Project Structure

```
parrot/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ single_channel/
â”‚   â””â”€â”€ double_channel/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ dual_llama.py
â”‚   â””â”€â”€ dual_phi.py
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ audio_processing.py
â”‚   â””â”€â”€ tokenization.py
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ pretrain.py
â”‚   â”œâ”€â”€ finetune.py
â”‚   â””â”€â”€ inference.py
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ usage_guide.md
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_models.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.py
â””â”€â”€ README.md
```


## License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.
