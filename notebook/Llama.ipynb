{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9acee31b-f8df-409e-a179-12be36414c4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T07:55:14.575489Z",
     "iopub.status.busy": "2024-09-24T07:55:14.575308Z",
     "iopub.status.idle": "2024-09-24T07:55:20.257607Z",
     "shell.execute_reply": "2024-09-24T07:55:20.256912Z",
     "shell.execute_reply.started": "2024-09-24T07:55:14.575474Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PhiForCausalLM were not initialized from the model checkpoint at /apdcephfs_qy3/share_1594716/bingzhe/pretrained/phi-1_5 and are newly initialized: ['model.channel_emb.channel_embedding.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from dual_llama import LlamaForCausalLM\n",
    "\n",
    "from dual_phi import PhiForCausalLM\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "\n",
    "# model_path = \"/apdcephfs_qy3/share_1594716/bingzhe/pretrained/Llama-2-7b-hf/\"\n",
    "# model = LlamaForCausalLM.from_pretrained(model_path, device_map=\"cpu\")\n",
    "\n",
    "\n",
    "model_path = \"/apdcephfs_qy3/share_1594716/bingzhe/pretrained/phi-1_5\"\n",
    "\n",
    "config = AutoConfig.from_pretrained(model_path)\n",
    "\n",
    "model = PhiForCausalLM.from_pretrained(model_path, device_map=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eec3fe8b-369b-4f92-8170-23b951ea9445",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T07:58:05.085658Z",
     "iopub.status.busy": "2024-09-24T07:58:05.085147Z",
     "iopub.status.idle": "2024-09-24T07:58:06.256673Z",
     "shell.execute_reply": "2024-09-24T07:58:06.255950Z",
     "shell.execute_reply.started": "2024-09-24T07:58:05.085615Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff0089f2644e483abbf79b118d7a117e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: model.embed_tokens.weight, requires_grad: True\n",
      "Parameter: model.layers.0.self_attn.q_proj.weight, requires_grad: True\n",
      "Parameter: model.layers.0.self_attn.q_proj.bias, requires_grad: True\n",
      "Parameter: model.layers.0.self_attn.k_proj.weight, requires_grad: True\n",
      "Parameter: model.layers.0.self_attn.k_proj.bias, requires_grad: True\n",
      "Parameter: model.layers.0.self_attn.v_proj.weight, requires_grad: True\n",
      "Parameter: model.layers.0.self_attn.v_proj.bias, requires_grad: True\n",
      "Parameter: model.layers.0.self_attn.dense.weight, requires_grad: True\n",
      "Parameter: model.layers.0.self_attn.dense.bias, requires_grad: True\n",
      "Parameter: model.layers.0.mlp.fc1.weight, requires_grad: True\n",
      "Parameter: model.layers.0.mlp.fc1.bias, requires_grad: True\n",
      "Parameter: model.layers.0.mlp.fc2.weight, requires_grad: True\n",
      "Parameter: model.layers.0.mlp.fc2.bias, requires_grad: True\n",
      "Parameter: model.layers.0.input_layernorm.weight, requires_grad: True\n",
      "Parameter: model.layers.0.input_layernorm.bias, requires_grad: True\n",
      "Parameter: model.layers.1.self_attn.q_proj.weight, requires_grad: True\n",
      "Parameter: model.layers.1.self_attn.q_proj.bias, requires_grad: True\n",
      "Parameter: model.layers.1.self_attn.k_proj.weight, requires_grad: True\n",
      "Parameter: model.layers.1.self_attn.k_proj.bias, requires_grad: True\n",
      "Parameter: model.layers.1.self_attn.v_proj.weight, requires_grad: True\n",
      "Parameter: model.layers.1.self_attn.v_proj.bias, requires_grad: True\n",
      "Parameter: model.layers.1.self_attn.dense.weight, requires_grad: True\n",
      "Parameter: model.layers.1.self_attn.dense.bias, requires_grad: True\n",
      "Parameter: model.layers.1.mlp.fc1.weight, requires_grad: True\n",
      "Parameter: model.layers.1.mlp.fc1.bias, requires_grad: True\n",
      "Parameter: model.layers.1.mlp.fc2.weight, requires_grad: True\n",
      "Parameter: model.layers.1.mlp.fc2.bias, requires_grad: True\n",
      "Parameter: model.layers.1.input_layernorm.weight, requires_grad: True\n",
      "Parameter: model.layers.1.input_layernorm.bias, requires_grad: True\n",
      "Parameter: model.layers.2.self_attn.q_proj.weight, requires_grad: True\n",
      "Parameter: model.layers.2.self_attn.q_proj.bias, requires_grad: True\n",
      "Parameter: model.layers.2.self_attn.k_proj.weight, requires_grad: True\n",
      "Parameter: model.layers.2.self_attn.k_proj.bias, requires_grad: True\n",
      "Parameter: model.layers.2.self_attn.v_proj.weight, requires_grad: True\n",
      "Parameter: model.layers.2.self_attn.v_proj.bias, requires_grad: True\n",
      "Parameter: model.layers.2.self_attn.dense.weight, requires_grad: True\n",
      "Parameter: model.layers.2.self_attn.dense.bias, requires_grad: True\n",
      "Parameter: model.layers.2.mlp.fc1.weight, requires_grad: True\n",
      "Parameter: model.layers.2.mlp.fc1.bias, requires_grad: True\n",
      "Parameter: model.layers.2.mlp.fc2.weight, requires_grad: True\n",
      "Parameter: model.layers.2.mlp.fc2.bias, requires_grad: True\n",
      "Parameter: model.layers.2.input_layernorm.weight, requires_grad: True\n",
      "Parameter: model.layers.2.input_layernorm.bias, requires_grad: True\n",
      "Parameter: model.layers.3.self_attn.q_proj.weight, requires_grad: True\n",
      "Parameter: model.layers.3.self_attn.q_proj.bias, requires_grad: True\n",
      "Parameter: model.layers.3.self_attn.k_proj.weight, requires_grad: True\n",
      "Parameter: model.layers.3.self_attn.k_proj.bias, requires_grad: True\n",
      "Parameter: model.layers.3.self_attn.v_proj.weight, requires_grad: True\n",
      "Parameter: model.layers.3.self_attn.v_proj.bias, requires_grad: True\n",
      "Parameter: model.layers.3.self_attn.dense.weight, requires_grad: True\n",
      "Parameter: model.layers.3.self_attn.dense.bias, requires_grad: True\n",
      "Parameter: model.layers.3.mlp.fc1.weight, requires_grad: True\n",
      "Parameter: model.layers.3.mlp.fc1.bias, requires_grad: True\n",
      "Parameter: model.layers.3.mlp.fc2.weight, requires_grad: True\n",
      "Parameter: model.layers.3.mlp.fc2.bias, requires_grad: True\n",
      "Parameter: model.layers.3.input_layernorm.weight, requires_grad: True\n",
      "Parameter: model.layers.3.input_layernorm.bias, requires_grad: True\n",
      "Parameter: model.layers.4.self_attn.q_proj.weight, requires_grad: True\n",
      "Parameter: model.layers.4.self_attn.q_proj.bias, requires_grad: True\n",
      "Parameter: model.layers.4.self_attn.k_proj.weight, requires_grad: True\n",
      "Parameter: model.layers.4.self_attn.k_proj.bias, requires_grad: True\n",
      "Parameter: model.layers.4.self_attn.v_proj.weight, requires_grad: True\n",
      "Parameter: model.layers.4.self_attn.v_proj.bias, requires_grad: True\n",
      "Parameter: model.layers.4.self_attn.dense.weight, requires_grad: True\n",
      "Parameter: model.layers.4.self_attn.dense.bias, requires_grad: True\n",
      "Parameter: model.layers.4.mlp.fc1.weight, requires_grad: True\n",
      "Parameter: model.layers.4.mlp.fc1.bias, requires_grad: True\n",
      "Parameter: model.layers.4.mlp.fc2.weight, requires_grad: True\n",
      "Parameter: model.layers.4.mlp.fc2.bias, requires_grad: True\n",
      "Parameter: model.layers.4.input_layernorm.weight, requires_grad: True\n",
      "Parameter: model.layers.4.input_layernorm.bias, requires_grad: True\n",
      "Parameter: model.layers.5.self_attn.q_proj.weight, requires_grad: True\n",
      "Parameter: model.layers.5.self_attn.q_proj.bias, requires_grad: True\n",
      "Parameter: model.layers.5.self_attn.k_proj.weight, requires_grad: True\n",
      "Parameter: model.layers.5.self_attn.k_proj.bias, requires_grad: True\n",
      "Parameter: model.layers.5.self_attn.v_proj.weight, requires_grad: True\n",
      "Parameter: model.layers.5.self_attn.v_proj.bias, requires_grad: True\n",
      "Parameter: model.layers.5.self_attn.dense.weight, requires_grad: True\n",
      "Parameter: model.layers.5.self_attn.dense.bias, requires_grad: True\n",
      "Parameter: model.layers.5.mlp.fc1.weight, requires_grad: True\n",
      "Parameter: model.layers.5.mlp.fc1.bias, requires_grad: True\n",
      "Parameter: model.layers.5.mlp.fc2.weight, requires_grad: True\n",
      "Parameter: model.layers.5.mlp.fc2.bias, requires_grad: True\n",
      "Parameter: model.layers.5.input_layernorm.weight, requires_grad: True\n",
      "Parameter: model.layers.5.input_layernorm.bias, requires_grad: True\n",
      "Parameter: model.layers.6.self_attn.q_proj.weight, requires_grad: True\n",
      "Parameter: model.layers.6.self_attn.q_proj.bias, requires_grad: True\n",
      "Parameter: model.layers.6.self_attn.k_proj.weight, requires_grad: True\n",
      "Parameter: model.layers.6.self_attn.k_proj.bias, requires_grad: True\n",
      "Parameter: model.layers.6.self_attn.v_proj.weight, requires_grad: True\n",
      "Parameter: model.layers.6.self_attn.v_proj.bias, requires_grad: True\n",
      "Parameter: model.layers.6.self_attn.dense.weight, requires_grad: True\n",
      "Parameter: model.layers.6.self_attn.dense.bias, requires_grad: True\n",
      "Parameter: model.layers.6.mlp.fc1.weight, requires_grad: True\n",
      "Parameter: model.layers.6.mlp.fc1.bias, requires_grad: True\n",
      "Parameter: model.layers.6.mlp.fc2.weight, requires_grad: True\n",
      "Parameter: model.layers.6.mlp.fc2.bias, requires_grad: True\n",
      "Parameter: model.layers.6.input_layernorm.weight, requires_grad: True\n",
      "Parameter: model.layers.6.input_layernorm.bias, requires_grad: True\n",
      "Parameter: model.layers.7.self_attn.q_proj.weight, requires_grad: True\n",
      "Parameter: model.layers.7.self_attn.q_proj.bias, requires_grad: True\n",
      "Parameter: model.layers.7.self_attn.k_proj.weight, requires_grad: True\n",
      "Parameter: model.layers.7.self_attn.k_proj.bias, requires_grad: True\n",
      "Parameter: model.layers.7.self_attn.v_proj.weight, requires_grad: True\n",
      "Parameter: model.layers.7.self_attn.v_proj.bias, requires_grad: True\n",
      "Parameter: model.layers.7.self_attn.dense.weight, requires_grad: True\n",
      "Parameter: model.layers.7.self_attn.dense.bias, requires_grad: True\n",
      "Parameter: model.layers.7.mlp.fc1.weight, requires_grad: True\n",
      "Parameter: model.layers.7.mlp.fc1.bias, requires_grad: True\n",
      "Parameter: model.layers.7.mlp.fc2.weight, requires_grad: True\n",
      "Parameter: model.layers.7.mlp.fc2.bias, requires_grad: True\n",
      "Parameter: model.layers.7.input_layernorm.weight, requires_grad: True\n",
      "Parameter: model.layers.7.input_layernorm.bias, requires_grad: True\n",
      "Parameter: model.layers.8.self_attn.q_proj.weight, requires_grad: True\n",
      "Parameter: model.layers.8.self_attn.q_proj.bias, requires_grad: True\n",
      "Parameter: model.layers.8.self_attn.k_proj.weight, requires_grad: True\n",
      "Parameter: model.layers.8.self_attn.k_proj.bias, requires_grad: True\n",
      "Parameter: model.layers.8.self_attn.v_proj.weight, requires_grad: True\n",
      "Parameter: model.layers.8.self_attn.v_proj.bias, requires_grad: True\n",
      "Parameter: model.layers.8.self_attn.dense.weight, requires_grad: True\n",
      "Parameter: model.layers.8.self_attn.dense.bias, requires_grad: True\n",
      "Parameter: model.layers.8.mlp.fc1.weight, requires_grad: True\n",
      "Parameter: model.layers.8.mlp.fc1.bias, requires_grad: True\n",
      "Parameter: model.layers.8.mlp.fc2.weight, requires_grad: True\n",
      "Parameter: model.layers.8.mlp.fc2.bias, requires_grad: True\n",
      "Parameter: model.layers.8.input_layernorm.weight, requires_grad: True\n",
      "Parameter: model.layers.8.input_layernorm.bias, requires_grad: True\n",
      "Parameter: model.layers.9.self_attn.q_proj.weight, requires_grad: True\n",
      "Parameter: model.layers.9.self_attn.q_proj.bias, requires_grad: True\n",
      "Parameter: model.layers.9.self_attn.k_proj.weight, requires_grad: True\n",
      "Parameter: model.layers.9.self_attn.k_proj.bias, requires_grad: True\n",
      "Parameter: model.layers.9.self_attn.v_proj.weight, requires_grad: True\n",
      "Parameter: model.layers.9.self_attn.v_proj.bias, requires_grad: True\n",
      "Parameter: model.layers.9.self_attn.dense.weight, requires_grad: True\n",
      "Parameter: model.layers.9.self_attn.dense.bias, requires_grad: True\n",
      "Parameter: model.layers.9.mlp.fc1.weight, requires_grad: True\n",
      "Parameter: model.layers.9.mlp.fc1.bias, requires_grad: True\n",
      "Parameter: model.layers.9.mlp.fc2.weight, requires_grad: True\n",
      "Parameter: model.layers.9.mlp.fc2.bias, requires_grad: True\n",
      "Parameter: model.layers.9.input_layernorm.weight, requires_grad: True\n",
      "Parameter: model.layers.9.input_layernorm.bias, requires_grad: True\n",
      "Parameter: model.layers.10.self_attn.q_proj.weight, requires_grad: True\n",
      "Parameter: model.layers.10.self_attn.q_proj.bias, requires_grad: True\n",
      "Parameter: model.layers.10.self_attn.k_proj.weight, requires_grad: True\n",
      "Parameter: model.layers.10.self_attn.k_proj.bias, requires_grad: True\n",
      "Parameter: model.layers.10.self_attn.v_proj.weight, requires_grad: True\n",
      "Parameter: model.layers.10.self_attn.v_proj.bias, requires_grad: True\n",
      "Parameter: model.layers.10.self_attn.dense.weight, requires_grad: True\n",
      "Parameter: model.layers.10.self_attn.dense.bias, requires_grad: True\n",
      "Parameter: model.layers.10.mlp.fc1.weight, requires_grad: True\n",
      "Parameter: model.layers.10.mlp.fc1.bias, requires_grad: True\n",
      "Parameter: model.layers.10.mlp.fc2.weight, requires_grad: True\n",
      "Parameter: model.layers.10.mlp.fc2.bias, requires_grad: True\n",
      "Parameter: model.layers.10.input_layernorm.weight, requires_grad: True\n",
      "Parameter: model.layers.10.input_layernorm.bias, requires_grad: True\n",
      "Parameter: model.layers.11.self_attn.q_proj.weight, requires_grad: True\n",
      "Parameter: model.layers.11.self_attn.q_proj.bias, requires_grad: True\n",
      "Parameter: model.layers.11.self_attn.k_proj.weight, requires_grad: True\n",
      "Parameter: model.layers.11.self_attn.k_proj.bias, requires_grad: True\n",
      "Parameter: model.layers.11.self_attn.v_proj.weight, requires_grad: True\n",
      "Parameter: model.layers.11.self_attn.v_proj.bias, requires_grad: True\n",
      "Parameter: model.layers.11.self_attn.dense.weight, requires_grad: True\n",
      "Parameter: model.layers.11.self_attn.dense.bias, requires_grad: True\n",
      "Parameter: model.layers.11.mlp.fc1.weight, requires_grad: True\n",
      "Parameter: model.layers.11.mlp.fc1.bias, requires_grad: True\n",
      "Parameter: model.layers.11.mlp.fc2.weight, requires_grad: True\n",
      "Parameter: model.layers.11.mlp.fc2.bias, requires_grad: True\n",
      "Parameter: model.layers.11.input_layernorm.weight, requires_grad: True\n",
      "Parameter: model.layers.11.input_layernorm.bias, requires_grad: True\n",
      "Parameter: model.layers.12.self_attn.q_proj.weight, requires_grad: True\n",
      "Parameter: model.layers.12.self_attn.q_proj.bias, requires_grad: True\n",
      "Parameter: model.layers.12.self_attn.k_proj.weight, requires_grad: True\n",
      "Parameter: model.layers.12.self_attn.k_proj.bias, requires_grad: True\n",
      "Parameter: model.layers.12.self_attn.v_proj.weight, requires_grad: True\n",
      "Parameter: model.layers.12.self_attn.v_proj.bias, requires_grad: True\n",
      "Parameter: model.layers.12.self_attn.dense.weight, requires_grad: True\n",
      "Parameter: model.layers.12.self_attn.dense.bias, requires_grad: True\n",
      "Parameter: model.layers.12.mlp.fc1.weight, requires_grad: True\n",
      "Parameter: model.layers.12.mlp.fc1.bias, requires_grad: True\n",
      "Parameter: model.layers.12.mlp.fc2.weight, requires_grad: True\n",
      "Parameter: model.layers.12.mlp.fc2.bias, requires_grad: True\n",
      "Parameter: model.layers.12.input_layernorm.weight, requires_grad: True\n",
      "Parameter: model.layers.12.input_layernorm.bias, requires_grad: True\n",
      "Parameter: model.layers.13.self_attn.q_proj.weight, requires_grad: True\n",
      "Parameter: model.layers.13.self_attn.q_proj.bias, requires_grad: True\n",
      "Parameter: model.layers.13.self_attn.k_proj.weight, requires_grad: True\n",
      "Parameter: model.layers.13.self_attn.k_proj.bias, requires_grad: True\n",
      "Parameter: model.layers.13.self_attn.v_proj.weight, requires_grad: True\n",
      "Parameter: model.layers.13.self_attn.v_proj.bias, requires_grad: True\n",
      "Parameter: model.layers.13.self_attn.dense.weight, requires_grad: True\n",
      "Parameter: model.layers.13.self_attn.dense.bias, requires_grad: True\n",
      "Parameter: model.layers.13.mlp.fc1.weight, requires_grad: True\n",
      "Parameter: model.layers.13.mlp.fc1.bias, requires_grad: True\n",
      "Parameter: model.layers.13.mlp.fc2.weight, requires_grad: True\n",
      "Parameter: model.layers.13.mlp.fc2.bias, requires_grad: True\n",
      "Parameter: model.layers.13.input_layernorm.weight, requires_grad: True\n",
      "Parameter: model.layers.13.input_layernorm.bias, requires_grad: True\n",
      "Parameter: model.layers.14.self_attn.q_proj.weight, requires_grad: True\n",
      "Parameter: model.layers.14.self_attn.q_proj.bias, requires_grad: True\n",
      "Parameter: model.layers.14.self_attn.k_proj.weight, requires_grad: True\n",
      "Parameter: model.layers.14.self_attn.k_proj.bias, requires_grad: True\n",
      "Parameter: model.layers.14.self_attn.v_proj.weight, requires_grad: True\n",
      "Parameter: model.layers.14.self_attn.v_proj.bias, requires_grad: True\n",
      "Parameter: model.layers.14.self_attn.dense.weight, requires_grad: True\n",
      "Parameter: model.layers.14.self_attn.dense.bias, requires_grad: True\n",
      "Parameter: model.layers.14.mlp.fc1.weight, requires_grad: True\n",
      "Parameter: model.layers.14.mlp.fc1.bias, requires_grad: True\n",
      "Parameter: model.layers.14.mlp.fc2.weight, requires_grad: True\n",
      "Parameter: model.layers.14.mlp.fc2.bias, requires_grad: True\n",
      "Parameter: model.layers.14.input_layernorm.weight, requires_grad: True\n",
      "Parameter: model.layers.14.input_layernorm.bias, requires_grad: True\n",
      "Parameter: model.layers.15.self_attn.q_proj.weight, requires_grad: True\n",
      "Parameter: model.layers.15.self_attn.q_proj.bias, requires_grad: True\n",
      "Parameter: model.layers.15.self_attn.k_proj.weight, requires_grad: True\n",
      "Parameter: model.layers.15.self_attn.k_proj.bias, requires_grad: True\n",
      "Parameter: model.layers.15.self_attn.v_proj.weight, requires_grad: True\n",
      "Parameter: model.layers.15.self_attn.v_proj.bias, requires_grad: True\n",
      "Parameter: model.layers.15.self_attn.dense.weight, requires_grad: True\n",
      "Parameter: model.layers.15.self_attn.dense.bias, requires_grad: True\n",
      "Parameter: model.layers.15.mlp.fc1.weight, requires_grad: True\n",
      "Parameter: model.layers.15.mlp.fc1.bias, requires_grad: True\n",
      "Parameter: model.layers.15.mlp.fc2.weight, requires_grad: True\n",
      "Parameter: model.layers.15.mlp.fc2.bias, requires_grad: True\n",
      "Parameter: model.layers.15.input_layernorm.weight, requires_grad: True\n",
      "Parameter: model.layers.15.input_layernorm.bias, requires_grad: True\n",
      "Parameter: model.layers.16.self_attn.q_proj.weight, requires_grad: True\n",
      "Parameter: model.layers.16.self_attn.q_proj.bias, requires_grad: True\n",
      "Parameter: model.layers.16.self_attn.k_proj.weight, requires_grad: True\n",
      "Parameter: model.layers.16.self_attn.k_proj.bias, requires_grad: True\n",
      "Parameter: model.layers.16.self_attn.v_proj.weight, requires_grad: True\n",
      "Parameter: model.layers.16.self_attn.v_proj.bias, requires_grad: True\n",
      "Parameter: model.layers.16.self_attn.dense.weight, requires_grad: True\n",
      "Parameter: model.layers.16.self_attn.dense.bias, requires_grad: True\n",
      "Parameter: model.layers.16.mlp.fc1.weight, requires_grad: True\n",
      "Parameter: model.layers.16.mlp.fc1.bias, requires_grad: True\n",
      "Parameter: model.layers.16.mlp.fc2.weight, requires_grad: True\n",
      "Parameter: model.layers.16.mlp.fc2.bias, requires_grad: True\n",
      "Parameter: model.layers.16.input_layernorm.weight, requires_grad: True\n",
      "Parameter: model.layers.16.input_layernorm.bias, requires_grad: True\n",
      "Parameter: model.layers.17.self_attn.q_proj.weight, requires_grad: True\n",
      "Parameter: model.layers.17.self_attn.q_proj.bias, requires_grad: True\n",
      "Parameter: model.layers.17.self_attn.k_proj.weight, requires_grad: True\n",
      "Parameter: model.layers.17.self_attn.k_proj.bias, requires_grad: True\n",
      "Parameter: model.layers.17.self_attn.v_proj.weight, requires_grad: True\n",
      "Parameter: model.layers.17.self_attn.v_proj.bias, requires_grad: True\n",
      "Parameter: model.layers.17.self_attn.dense.weight, requires_grad: True\n",
      "Parameter: model.layers.17.self_attn.dense.bias, requires_grad: True\n",
      "Parameter: model.layers.17.mlp.fc1.weight, requires_grad: True\n",
      "Parameter: model.layers.17.mlp.fc1.bias, requires_grad: True\n",
      "Parameter: model.layers.17.mlp.fc2.weight, requires_grad: True\n",
      "Parameter: model.layers.17.mlp.fc2.bias, requires_grad: True\n",
      "Parameter: model.layers.17.input_layernorm.weight, requires_grad: True\n",
      "Parameter: model.layers.17.input_layernorm.bias, requires_grad: True\n",
      "Parameter: model.layers.18.self_attn.q_proj.weight, requires_grad: True\n",
      "Parameter: model.layers.18.self_attn.q_proj.bias, requires_grad: True\n",
      "Parameter: model.layers.18.self_attn.k_proj.weight, requires_grad: True\n",
      "Parameter: model.layers.18.self_attn.k_proj.bias, requires_grad: True\n",
      "Parameter: model.layers.18.self_attn.v_proj.weight, requires_grad: True\n",
      "Parameter: model.layers.18.self_attn.v_proj.bias, requires_grad: True\n",
      "Parameter: model.layers.18.self_attn.dense.weight, requires_grad: True\n",
      "Parameter: model.layers.18.self_attn.dense.bias, requires_grad: True\n",
      "Parameter: model.layers.18.mlp.fc1.weight, requires_grad: True\n",
      "Parameter: model.layers.18.mlp.fc1.bias, requires_grad: True\n",
      "Parameter: model.layers.18.mlp.fc2.weight, requires_grad: True\n",
      "Parameter: model.layers.18.mlp.fc2.bias, requires_grad: True\n",
      "Parameter: model.layers.18.input_layernorm.weight, requires_grad: True\n",
      "Parameter: model.layers.18.input_layernorm.bias, requires_grad: True\n",
      "Parameter: model.layers.19.self_attn.q_proj.weight, requires_grad: True\n",
      "Parameter: model.layers.19.self_attn.q_proj.bias, requires_grad: True\n",
      "Parameter: model.layers.19.self_attn.k_proj.weight, requires_grad: True\n",
      "Parameter: model.layers.19.self_attn.k_proj.bias, requires_grad: True\n",
      "Parameter: model.layers.19.self_attn.v_proj.weight, requires_grad: True\n",
      "Parameter: model.layers.19.self_attn.v_proj.bias, requires_grad: True\n",
      "Parameter: model.layers.19.self_attn.dense.weight, requires_grad: True\n",
      "Parameter: model.layers.19.self_attn.dense.bias, requires_grad: True\n",
      "Parameter: model.layers.19.mlp.fc1.weight, requires_grad: True\n",
      "Parameter: model.layers.19.mlp.fc1.bias, requires_grad: True\n",
      "Parameter: model.layers.19.mlp.fc2.weight, requires_grad: True\n",
      "Parameter: model.layers.19.mlp.fc2.bias, requires_grad: True\n",
      "Parameter: model.layers.19.input_layernorm.weight, requires_grad: True\n",
      "Parameter: model.layers.19.input_layernorm.bias, requires_grad: True\n",
      "Parameter: model.layers.20.self_attn.q_proj.weight, requires_grad: True\n",
      "Parameter: model.layers.20.self_attn.q_proj.bias, requires_grad: True\n",
      "Parameter: model.layers.20.self_attn.k_proj.weight, requires_grad: True\n",
      "Parameter: model.layers.20.self_attn.k_proj.bias, requires_grad: True\n",
      "Parameter: model.layers.20.self_attn.v_proj.weight, requires_grad: True\n",
      "Parameter: model.layers.20.self_attn.v_proj.bias, requires_grad: True\n",
      "Parameter: model.layers.20.self_attn.dense.weight, requires_grad: True\n",
      "Parameter: model.layers.20.self_attn.dense.bias, requires_grad: True\n",
      "Parameter: model.layers.20.mlp.fc1.weight, requires_grad: True\n",
      "Parameter: model.layers.20.mlp.fc1.bias, requires_grad: True\n",
      "Parameter: model.layers.20.mlp.fc2.weight, requires_grad: True\n",
      "Parameter: model.layers.20.mlp.fc2.bias, requires_grad: True\n",
      "Parameter: model.layers.20.input_layernorm.weight, requires_grad: True\n",
      "Parameter: model.layers.20.input_layernorm.bias, requires_grad: True\n",
      "Parameter: model.layers.21.self_attn.q_proj.weight, requires_grad: True\n",
      "Parameter: model.layers.21.self_attn.q_proj.bias, requires_grad: True\n",
      "Parameter: model.layers.21.self_attn.k_proj.weight, requires_grad: True\n",
      "Parameter: model.layers.21.self_attn.k_proj.bias, requires_grad: True\n",
      "Parameter: model.layers.21.self_attn.v_proj.weight, requires_grad: True\n",
      "Parameter: model.layers.21.self_attn.v_proj.bias, requires_grad: True\n",
      "Parameter: model.layers.21.self_attn.dense.weight, requires_grad: True\n",
      "Parameter: model.layers.21.self_attn.dense.bias, requires_grad: True\n",
      "Parameter: model.layers.21.mlp.fc1.weight, requires_grad: True\n",
      "Parameter: model.layers.21.mlp.fc1.bias, requires_grad: True\n",
      "Parameter: model.layers.21.mlp.fc2.weight, requires_grad: True\n",
      "Parameter: model.layers.21.mlp.fc2.bias, requires_grad: True\n",
      "Parameter: model.layers.21.input_layernorm.weight, requires_grad: True\n",
      "Parameter: model.layers.21.input_layernorm.bias, requires_grad: True\n",
      "Parameter: model.layers.22.self_attn.q_proj.weight, requires_grad: True\n",
      "Parameter: model.layers.22.self_attn.q_proj.bias, requires_grad: True\n",
      "Parameter: model.layers.22.self_attn.k_proj.weight, requires_grad: True\n",
      "Parameter: model.layers.22.self_attn.k_proj.bias, requires_grad: True\n",
      "Parameter: model.layers.22.self_attn.v_proj.weight, requires_grad: True\n",
      "Parameter: model.layers.22.self_attn.v_proj.bias, requires_grad: True\n",
      "Parameter: model.layers.22.self_attn.dense.weight, requires_grad: True\n",
      "Parameter: model.layers.22.self_attn.dense.bias, requires_grad: True\n",
      "Parameter: model.layers.22.mlp.fc1.weight, requires_grad: True\n",
      "Parameter: model.layers.22.mlp.fc1.bias, requires_grad: True\n",
      "Parameter: model.layers.22.mlp.fc2.weight, requires_grad: True\n",
      "Parameter: model.layers.22.mlp.fc2.bias, requires_grad: True\n",
      "Parameter: model.layers.22.input_layernorm.weight, requires_grad: True\n",
      "Parameter: model.layers.22.input_layernorm.bias, requires_grad: True\n",
      "Parameter: model.layers.23.self_attn.q_proj.weight, requires_grad: True\n",
      "Parameter: model.layers.23.self_attn.q_proj.bias, requires_grad: True\n",
      "Parameter: model.layers.23.self_attn.k_proj.weight, requires_grad: True\n",
      "Parameter: model.layers.23.self_attn.k_proj.bias, requires_grad: True\n",
      "Parameter: model.layers.23.self_attn.v_proj.weight, requires_grad: True\n",
      "Parameter: model.layers.23.self_attn.v_proj.bias, requires_grad: True\n",
      "Parameter: model.layers.23.self_attn.dense.weight, requires_grad: True\n",
      "Parameter: model.layers.23.self_attn.dense.bias, requires_grad: True\n",
      "Parameter: model.layers.23.mlp.fc1.weight, requires_grad: True\n",
      "Parameter: model.layers.23.mlp.fc1.bias, requires_grad: True\n",
      "Parameter: model.layers.23.mlp.fc2.weight, requires_grad: True\n",
      "Parameter: model.layers.23.mlp.fc2.bias, requires_grad: True\n",
      "Parameter: model.layers.23.input_layernorm.weight, requires_grad: True\n",
      "Parameter: model.layers.23.input_layernorm.bias, requires_grad: True\n",
      "Parameter: model.final_layernorm.weight, requires_grad: True\n",
      "Parameter: model.final_layernorm.bias, requires_grad: True\n",
      "Parameter: model.channel_emb.channel_embedding.weight, requires_grad: True\n",
      "Parameter: lm_head.weight, requires_grad: True\n",
      "Parameter: lm_head.bias, requires_grad: True\n"
     ]
    }
   ],
   "source": [
    "model_new = PhiForCausalLM.from_pretrained(\"phi\", device_map=\"cpu\")\n",
    "\n",
    "for name, param in model_new.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"Parameter: {name}, requires_grad: {param.requires_grad}\")\n",
    "    else:\n",
    "        print(f\"Parameter: {name}, requires_grad: {param.requires_grad} (not tracking gradients)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e68ace3e-c0e6-4809-b92b-6ab73420b9a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T13:16:09.558125Z",
     "iopub.status.busy": "2024-09-23T13:16:09.557578Z",
     "iopub.status.idle": "2024-09-23T13:16:09.659333Z",
     "shell.execute_reply": "2024-09-23T13:16:09.658549Z",
     "shell.execute_reply.started": "2024-09-23T13:16:09.558103Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_path, padding_sided=\"left\")\n",
    "tokenizer.pad_token_id = 0\n",
    "tokenizer.eos_token_id = 2\n",
    "tokenizer.padding_side = \"left\"\n",
    "\n",
    "\n",
    "prompt = ['''def remove_non_ascii(s: str) -> str:\n",
    "    \"\"\" <FILL_ME>\n",
    "    return result\n",
    "''', \"hello, my name is Jack\"]\n",
    "\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\", padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6eb7997d-0bdf-4b92-8b90-4558b884fc19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T13:16:11.470740Z",
     "iopub.status.busy": "2024-09-23T13:16:11.470227Z",
     "iopub.status.idle": "2024-09-23T13:16:11.476283Z",
     "shell.execute_reply": "2024-09-23T13:16:11.475755Z",
     "shell.execute_reply.started": "2024-09-23T13:16:11.470719Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 4299,  4781,    62, 13159,    62,   292,   979,    72,     7,    82,\n",
       "            25,   965,     8,  4613,   965,    25,   198, 50284, 37811,  1279,\n",
       "            37,  8267,    62, 11682,    29,   198, 50284,  7783,  1255,   198],\n",
       "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0, 31373,    11,   616,  1438,   318,  3619]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b161f43-ecef-41ad-b32b-09a894f52073",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T07:54:03.175097Z",
     "iopub.status.busy": "2024-09-24T07:54:03.174760Z",
     "iopub.status.idle": "2024-09-24T07:54:03.188915Z",
     "shell.execute_reply": "2024-09-24T07:54:03.188216Z",
     "shell.execute_reply.started": "2024-09-24T07:54:03.175078Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67146ef6-e297-49f8-a741-f6c53f1dc7a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T07:55:50.191893Z",
     "iopub.status.busy": "2024-09-24T07:55:50.191299Z",
     "iopub.status.idle": "2024-09-24T07:55:58.607483Z",
     "shell.execute_reply": "2024-09-24T07:55:58.606634Z",
     "shell.execute_reply.started": "2024-09-24T07:55:50.191870Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.save_pretrained(\"phi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c1678f0-9ce1-459b-94f8-3d6ee8595784",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T13:16:41.520917Z",
     "iopub.status.busy": "2024-09-23T13:16:41.520431Z",
     "iopub.status.idle": "2024-09-23T13:16:44.394350Z",
     "shell.execute_reply": "2024-09-23T13:16:44.393552Z",
     "shell.execute_reply.started": "2024-09-23T13:16:41.520896Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4299,  4781,    62, 13159,    62,   292,   979,    72,     7,    82,\n",
       "            25,   965,     8,  4613,   965,    25,   198, 50284, 37811,  1279,\n",
       "            37,  8267,    62, 11682,    29,   198, 50284,  7783,  1255,   198,\n",
       "            25, 50284,   198, 37811, 50284,   198,  7783, 50284,   705,  7783],\n",
       "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0, 31373,    11,   616,  1438,   318,  3619,\n",
       "           340,    13,   338,   314,   257,  1101,  1643,  9675,   286,   345]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model.generate(\n",
    "    **input_ids,\n",
    "    max_new_tokens=105,\n",
    "    pad_token_id=0,\n",
    "    do_sample=False,\n",
    "    max_length=40\n",
    ")\n",
    "# model(**input_ids)\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "93de180b-8da0-493c-bd24-87aafb0449e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T13:22:07.332214Z",
     "iopub.status.busy": "2024-09-23T13:22:07.331599Z",
     "iopub.status.idle": "2024-09-23T13:22:07.337507Z",
     "shell.execute_reply": "2024-09-23T13:22:07.336977Z",
     "shell.execute_reply.started": "2024-09-23T13:22:07.332188Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def remove_non_ascii(s: str) -> str:\\n    \"\"\" <FILL_ME>\\n    return result\\n:    \\n\"\"\"    \\nreturn    \\'return'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output\n",
    "tokenizer.decode(output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2c81efff-93c5-4465-9e41-389a9b609235",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T13:22:05.604722Z",
     "iopub.status.busy": "2024-09-23T13:22:05.604169Z",
     "iopub.status.idle": "2024-09-23T13:22:05.609870Z",
     "shell.execute_reply": "2024-09-23T13:22:05.609324Z",
     "shell.execute_reply.started": "2024-09-23T13:22:05.604699Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"!!!!!!!!!!!!!!!!!!!!!!!!hello, my name is Jack it.'s I a'm bit glad of you\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output\n",
    "tokenizer.decode(output[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "765076c9-c0ed-49b3-8b3d-be7b3a0fb44c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-22T09:06:38.882480Z",
     "iopub.status.busy": "2024-09-22T09:06:38.882349Z",
     "iopub.status.idle": "2024-09-22T09:06:38.897796Z",
     "shell.execute_reply": "2024-09-22T09:06:38.897077Z",
     "shell.execute_reply.started": "2024-09-22T09:06:38.882469Z"
    }
   },
   "outputs": [],
   "source": [
    "unsqueeze_dim = 1\n",
    "position_ids = 30\n",
    "cos = torch.rand([1, 30, 128]) * 0.3\n",
    "sin = torch.rand([1, 30, 128]) \n",
    "q = torch.rand([1, 32, 30, 128])\n",
    "k = torch.rand([1, 32, 30, 128])\n",
    "position_ids = torch.arange(30)\n",
    "\n",
    "\n",
    "def rotate_half(x):\n",
    "    \"\"\"Rotates half the hidden dims of the input.\"\"\"\n",
    "    x1 = x[..., : x.shape[-1] // 2]\n",
    "    x2 = x[..., x.shape[-1] // 2 :]\n",
    "    return torch.cat((-x2, x1), dim=-1)\n",
    "\n",
    "if position_ids is not None:\n",
    "    # Assuming position_ids is of shape [batch_size, seq_len]\n",
    "    # We need to create a new position_ids that groups adjacent tokens\n",
    "    new_position_ids = position_ids // 2  # Grouping adjacent tokens\n",
    "else:\n",
    "    # If position_ids is not provided, we create a default one\n",
    "    seq_len = q.size(2)  # Assuming q has shape [batch_size, heads, seq_len, head_dim]\n",
    "    new_position_ids = torch.arange(seq_len, device=q.device) // 2  # Grouping adjacent tokens\n",
    "\n",
    "# Get the cosine and sine values for the new position ids\n",
    "cos = cos[:, new_position_ids, :]\n",
    "sin = sin[:, new_position_ids, :]\n",
    "\n",
    "cos = cos.unsqueeze(unsqueeze_dim)\n",
    "sin = sin.unsqueeze(unsqueeze_dim)\n",
    "\n",
    "q_embed = (q * cos) + (rotate_half(q) * sin)\n",
    "k_embed = (k * cos) + (rotate_half(k) * sin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e712722e-35dc-4ec4-8a16-27478434b16c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabb2b07-df35-4b2d-b79d-bcff2ba003dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3196c9c6-4d57-415e-a5fa-b2962668db72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-22T09:06:38.898851Z",
     "iopub.status.busy": "2024-09-22T09:06:38.898493Z",
     "iopub.status.idle": "2024-09-22T09:06:38.902302Z",
     "shell.execute_reply": "2024-09-22T09:06:38.901840Z",
     "shell.execute_reply.started": "2024-09-22T09:06:38.898837Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 30, 128])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8aa1bcfb-d7f4-426f-9a57-c50eafe0545f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-22T09:06:38.903190Z",
     "iopub.status.busy": "2024-09-22T09:06:38.902870Z",
     "iopub.status.idle": "2024-09-22T09:06:38.905635Z",
     "shell.execute_reply": "2024-09-22T09:06:38.905169Z",
     "shell.execute_reply.started": "2024-09-22T09:06:38.903177Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers.configuration_utils import PretrainedConfig\n",
    "from transformers.modeling_rope_utils import rope_config_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ddffbaf1-5e8b-411f-a76b-5e200c66479f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-22T09:06:38.906477Z",
     "iopub.status.busy": "2024-09-22T09:06:38.906208Z",
     "iopub.status.idle": "2024-09-22T09:06:38.910210Z",
     "shell.execute_reply": "2024-09-22T09:06:38.909738Z",
     "shell.execute_reply.started": "2024-09-22T09:06:38.906464Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "result_1 = 500 ** 50\n",
    "result_2 = 1000 ** 20\n",
    "\n",
    "result_1 < result_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec31a5fd-32a4-447a-97a9-a5a604ef638a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-22T09:06:38.910909Z",
     "iopub.status.busy": "2024-09-22T09:06:38.910777Z",
     "iopub.status.idle": "2024-09-22T09:06:38.914146Z",
     "shell.execute_reply": "2024-09-22T09:06:38.913675Z",
     "shell.execute_reply.started": "2024-09-22T09:06:38.910898Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def precompute_freqs_cis(dim: int, end: int, theta: float = 10000.0):\n",
    "    freqs = 1.0 / (theta ** (torch.arange(0, dim, 2)[: (dim // 2)].float() / dim))\n",
    "    t = torch.arange(end, device=freqs.device)  # type: ignore\n",
    "    freqs = torch.outer(t, freqs).float()  # type: ignore\n",
    "    freqs_cis = torch.polar(torch.ones_like(freqs), freqs)  # complex64\n",
    "    return freqs_cis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8c0f8bd-00c3-48d2-9ee4-088e6599277c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-22T09:06:38.915070Z",
     "iopub.status.busy": "2024-09-22T09:06:38.914726Z",
     "iopub.status.idle": "2024-09-22T09:06:38.921143Z",
     "shell.execute_reply": "2024-09-22T09:06:38.920564Z",
     "shell.execute_reply.started": "2024-09-22T09:06:38.915057Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "dim = 4096\n",
    "end = 100\n",
    "theta = 10000\n",
    "freqs = 1.0 / (theta ** (torch.arange(0, dim, 2)[: (dim // 2)].float() / dim))\n",
    "t = torch.arange(end, device=freqs.device)  # type: ignore\n",
    "freqs = torch.outer(t, freqs).float()  # type: ignore\n",
    "freqs_cis = torch.polar(torch.ones_like(freqs), freqs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0c7c68e-a05c-47ab-a095-54e0ed478198",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-22T09:06:38.921873Z",
     "iopub.status.busy": "2024-09-22T09:06:38.921706Z",
     "iopub.status.idle": "2024-09-22T09:06:38.926902Z",
     "shell.execute_reply": "2024-09-22T09:06:38.926459Z",
     "shell.execute_reply.started": "2024-09-22T09:06:38.921860Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000e+00, 2.0000e+00, 4.0000e+00,  ..., 4.0900e+03, 4.0920e+03,\n",
       "        4.0940e+03])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(0, dim, 2)[: (dim // 2)].float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "786a9693-51a8-4484-87b3-97a9d337bda6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-22T09:06:38.927545Z",
     "iopub.status.busy": "2024-09-22T09:06:38.927416Z",
     "iopub.status.idle": "2024-09-22T09:06:38.930931Z",
     "shell.execute_reply": "2024-09-22T09:06:38.930474Z",
     "shell.execute_reply.started": "2024-09-22T09:06:38.927534Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2048])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.arange(0, dim, 2)[: (dim // 2)].float() / dim).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea27c305-8134-4692-b9dc-59b070285a96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-22T09:06:38.937665Z",
     "iopub.status.busy": "2024-09-22T09:06:38.937360Z",
     "iopub.status.idle": "2024-09-22T09:06:38.940548Z",
     "shell.execute_reply": "2024-09-22T09:06:38.940112Z",
     "shell.execute_reply.started": "2024-09-22T09:06:38.937652Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c11c79d-f221-45db-81c1-a551b4146c9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
